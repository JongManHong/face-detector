{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.24313726  0.38431373  0.47058824]\n",
      "  [ 0.15686275  0.3019608   0.43529412]\n",
      "  [ 0.26666668  0.41960785  0.55686277]\n",
      "  ..., \n",
      "  [ 0.88235295  0.88235295  0.88235295]\n",
      "  [ 0.88235295  0.88235295  0.88235295]\n",
      "  [ 0.88235295  0.88235295  0.88235295]]\n",
      "\n",
      " [[ 0.38039216  0.52156866  0.55686277]\n",
      "  [ 0.27450982  0.35294119  0.44313726]\n",
      "  [ 0.47450981  0.61960787  0.65490198]\n",
      "  ..., \n",
      "  [ 0.88235295  0.88235295  0.88235295]\n",
      "  [ 0.88235295  0.88235295  0.88235295]\n",
      "  [ 0.88235295  0.88235295  0.88235295]]\n",
      "\n",
      " [[ 0.47058824  0.63137257  0.65490198]\n",
      "  [ 0.26666668  0.35294119  0.43137255]\n",
      "  [ 0.32549021  0.4627451   0.52549022]\n",
      "  ..., \n",
      "  [ 0.88235295  0.88235295  0.88235295]\n",
      "  [ 0.88235295  0.88235295  0.88235295]\n",
      "  [ 0.88235295  0.88235295  0.88235295]]\n",
      "\n",
      " ..., \n",
      " [[ 0.39607844  0.56078434  0.50980395]\n",
      "  [ 0.26666668  0.42745098  0.40784314]\n",
      "  [ 0.60000002  0.70588237  0.7019608 ]\n",
      "  ..., \n",
      "  [ 0.76078433  0.80000001  0.81960785]\n",
      "  [ 0.68235296  0.74901962  0.78823531]\n",
      "  [ 0.65098041  0.75294119  0.79607844]]\n",
      "\n",
      " [[ 0.42352942  0.57647061  0.50980395]\n",
      "  [ 0.25882354  0.40000001  0.3882353 ]\n",
      "  [ 0.40000001  0.54509807  0.53333336]\n",
      "  ..., \n",
      "  [ 0.87450981  0.88235295  0.88235295]\n",
      "  [ 0.82352942  0.85882354  0.86666667]\n",
      "  [ 0.85882354  0.88235295  0.87843138]]\n",
      "\n",
      " [[ 0.37254903  0.53333336  0.47058824]\n",
      "  [ 0.26274511  0.41568628  0.39607844]\n",
      "  [ 0.33333334  0.49411765  0.47058824]\n",
      "  ..., \n",
      "  [ 0.88235295  0.88235295  0.88235295]\n",
      "  [ 0.74901962  0.80392158  0.83529413]\n",
      "  [ 0.62352943  0.7019608   0.76862746]]]\n",
      "Tensor(\"rgb_to_grayscale:0\", shape=(48, 48, 1), dtype=float32)\n",
      "Tensor(\"Reshape_1:0\", shape=(1, 32, 32, 1), dtype=float32)\n",
      "Tensor(\"Reshape_2:0\", shape=(1,), dtype=int32)\n",
      "Checkpoint file path: ./model.ckpt-8000\n",
      "-----------------------------------------------------\n",
      "LABEL FOR INPUT IMAGE: [[-0.63804251  3.1481185   4.29016924  6.60741711 -4.44842672 -4.46447945\n",
      "  -4.44236326]] -> [3] Sad\n",
      "-----------------------------------------------------\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To exit: use 'exit', 'quit', or Ctrl-D.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Evaluation for FER2013.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import misc\n",
    "\n",
    "import fer2013_2\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('eval_dir', './tmp/fer2013_eval',\n",
    "                           \"\"\"Directory where to write event logs.\"\"\")\n",
    "tf.app.flags.DEFINE_string('eval_data', 'test',\n",
    "                           \"\"\"Either 'test' or 'train_eval'.\"\"\")\n",
    "tf.app.flags.DEFINE_string('checkpoint_dir', './',\n",
    "                           \"\"\"Directory where to read model checkpoints.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('eval_interval_secs', 60 * 5,\n",
    "                            \"\"\"How often to run the eval.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('num_examples', 3589,\n",
    "                            \"\"\"Number of examples to run.\"\"\")\n",
    "tf.app.flags.DEFINE_boolean('run_once', True,\n",
    "                         \"\"\"Whether to run eval only once.\"\"\")\n",
    "\n",
    "\n",
    "def eval_once(saver, summary_writer, logits, labels, top_k_op, summary_op):\n",
    "  # print(\"Called eval_once ...\")\n",
    "  \"\"\"Run Eval once.\n",
    "  Args:\n",
    "    saver: Saver.\n",
    "    summary_writer: Summary writer.\n",
    "    top_k_op: Top K op.\n",
    "    summary_op: Summary op.\n",
    "  \"\"\"\n",
    "  with tf.Session() as sess:\n",
    "    ckpt = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "      # Restores from checkpoint\n",
    "      saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "      print(\"Checkpoint file path:\", ckpt.model_checkpoint_path)\n",
    "      # Assuming model_checkpoint_path looks something like:\n",
    "      #   /my-favorite-path/fer2013_train/model.ckpt-0,\n",
    "      # extract global_step from it.\n",
    "      global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "    else:\n",
    "      print('No checkpoint file found')\n",
    "      return\n",
    "\n",
    "    # Start the queue runners.\n",
    "    coord = tf.train.Coordinator()\n",
    "    try:\n",
    "      threads = []\n",
    "      for qr in tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS):\n",
    "        threads.extend(qr.create_threads(sess, coord=coord, daemon=True,\n",
    "                                         start=True))\n",
    "\n",
    "      num_iter = int(math.ceil(FLAGS.num_examples / FLAGS.batch_input_size))\n",
    "      true_count = 0  # Counts the number of correct predictions.\n",
    "      total_sample_count = num_iter * FLAGS.batch_input_size\n",
    "      step = 0\n",
    "      time.sleep(1)\n",
    "\n",
    "      # print(\"step = %d, num_iter = %d  \" % (step, num_iter))\n",
    "\n",
    "      emotion_dict = {0: 'Angry', 1: 'Fear', 2: 'Happy', 3: 'Sad'}\n",
    "\n",
    "      while step < num_iter and not coord.should_stop():\n",
    "        # print(\"Inside while ...\")\n",
    "        result1, result2  = sess.run([logits, labels])\n",
    "        #label = sess.run(labels)\n",
    "        # print('Step:', step, 'result',result1, 'Label:', result2)\n",
    "        c = sess.run(tf.arg_max(result1, 1))\n",
    "        \n",
    "        print(\"-----------------------------------------------------\")\n",
    "        print('LABEL FOR INPUT IMAGE:', result1, '->', c, emotion_dict[c[0]])\n",
    "        print(\"-----------------------------------------------------\")\n",
    "        step += 1\n",
    "        break\n",
    "\n",
    "      # print(\"Exited while! Next...\")\n",
    "\n",
    "      # Compute precision @ 1.\n",
    "      precision = true_count / step\n",
    "      # print('Summary -- Step:', step, 'Accurcy:',true_count * 100.0 / step * 1.0, )\n",
    "      # print('%s: total:%d true:%d precision @ 1 = %.3f' % (datetime.now(), total_sample_count, true_count, precision))\n",
    "\n",
    "    except Exception as e:  # pylint: disable=broad-except\n",
    "      coord.request_stop(e)\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads, stop_grace_period_secs=10)\n",
    "\n",
    "\n",
    "def evaluate():\n",
    "  \"\"\"Eval FER2013 for a number of steps.\"\"\"\n",
    "\n",
    "  img1 = plt.imread('saved_frame2.png')\n",
    "    \n",
    "  plt.imshow(img1) \n",
    "\n",
    "  with tf.Graph().as_default():\n",
    "    # Get images and labels for FER2013.\n",
    "    eval_data = FLAGS.eval_data == 'test'\n",
    "    # images, labels = fer2013.inputs(eval_data=eval_data)\n",
    "\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.\n",
    "   \n",
    "    img = tf.image.rgb_to_grayscale(img1)\n",
    "\n",
    "    distorted_image = tf.image.resize_image_with_crop_or_pad(img, 32, 32)\n",
    "    distorted_image = tf.image.random_brightness(distorted_image, max_delta=63)\n",
    "    distorted_image = tf.image.random_contrast(distorted_image, lower=0.2, upper=1.8)\n",
    "    float_image = tf.image.per_image_whitening(distorted_image)  \n",
    "    float_image = tf.reshape(float_image, [1, 32, 32, 1])\n",
    "    print(img1)\n",
    "    print(img)\n",
    "    print(float_image)\n",
    "    \n",
    "    logits = fer2013_2.inference(float_image)\n",
    "\n",
    "    # Calculate predictions.\n",
    "    labels = tf.reshape(tf.constant(12), [1])\n",
    "    \n",
    "    print(labels)\n",
    "    \n",
    "    top_k_op = tf.nn.in_top_k(logits, labels, 1)\n",
    "\n",
    "    # Restore the moving average version of the learned variables for eval.\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(\n",
    "        fer2013_2.MOVING_AVERAGE_DECAY)\n",
    "    variables_to_restore = variable_averages.variables_to_restore()\n",
    "    saver = tf.train.Saver(variables_to_restore)\n",
    "    \n",
    "    # Build the summary operation based on the TF collection of Summaries.\n",
    "    summary_op = tf.merge_all_summaries()\n",
    "\n",
    "    graph_def = tf.get_default_graph().as_graph_def()\n",
    "    summary_writer = tf.train.SummaryWriter(FLAGS.eval_dir,\n",
    "                                            graph_def=graph_def)\n",
    "\n",
    "    while True:\n",
    "      eval_once(saver, summary_writer, logits, labels, top_k_op, summary_op)\n",
    "\n",
    "      if FLAGS.run_once:\n",
    "        break\n",
    "      time.sleep(FLAGS.eval_interval_secs)\n",
    "\n",
    "\n",
    "def main(argv=None):\n",
    "  if tf.gfile.Exists(FLAGS.eval_dir):\n",
    "    tf.gfile.DeleteRecursively(FLAGS.eval_dir)\n",
    "  tf.gfile.MakeDirs(FLAGS.eval_dir)\n",
    "  evaluate()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
